{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_Basic_RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1a8LCrswEuRiP+wP9S9a3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BarryLiu-97/Pytorch-Tutorial/blob/master/10_Basic_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jVRmVq3sUb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsuGv3ZeRh_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1\n",
        "seq_len = 3\n",
        "input_size = 4\n",
        "hidden_size = 2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aPmQSsWTIas",
        "colab_type": "text"
      },
      "source": [
        "# 示例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oWAYk9fR0nr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cell = torch.nn.RNNCell(input_size=input_size, hidden_size=hidden_size)\n",
        "#(seq, batch, features)\n",
        "dataset = torch.randn(seq_len, batch_size, input_size)\n",
        "hidden = torch.zeros(batch_size, hidden_size)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml18i9HLSH7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "4482f6e2-da3e-4e71-e49c-9341032ba0f8"
      },
      "source": [
        "for idx, input in enumerate(dataset):\n",
        "  print('=' * 20, idx, '=' * 20)\n",
        "  print('Input size:', input.shape)\n",
        "\n",
        "  hidden = cell(input, hidden)\n",
        "\n",
        "  print('outputs size:', hidden.shape)\n",
        "  print(hidden)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================== 0 ====================\n",
            "Input size: torch.Size([1, 4])\n",
            "outputs size: torch.Size([1, 2])\n",
            "tensor([[0.4127, 0.9934]], grad_fn=<TanhBackward>)\n",
            "==================== 1 ====================\n",
            "Input size: torch.Size([1, 4])\n",
            "outputs size: torch.Size([1, 2])\n",
            "tensor([[-0.8046, -0.6573]], grad_fn=<TanhBackward>)\n",
            "==================== 2 ====================\n",
            "Input size: torch.Size([1, 4])\n",
            "outputs size: torch.Size([1, 2])\n",
            "tensor([[ 0.8152, -0.0012]], grad_fn=<TanhBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzBjMOdZS_qq",
        "colab_type": "text"
      },
      "source": [
        "# 使用RNN  \n",
        "cell中  \n",
        "input表示整个输入序列  \n",
        "hidden表示h<sub>0</sub>  \n",
        "输出中   \n",
        "out表示h<sub>1</sub>～h<sub>N</sub>   \n",
        "hidden表示h<sub>N</sub>    \n",
        "input of shape(SeqSize, batch, input_size)  \n",
        "hidden of shape(numLayers, batch, hidden_size)  \n",
        "output of shape(SeqLen, batch, hidden_size)  \n",
        "hidden of shape(numLayers, batch, hidden_size) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcdi9XSpVbcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1\n",
        "seq_len = 3\n",
        "input_size = 4\n",
        "hidden_size = 2\n",
        "num_layers = 1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luocb9l5TATv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cell = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size)\n",
        "\n",
        "#(seq, batch, features)\n",
        "inputs = torch.randn(seq_len, batch_size, input_size)\n",
        "hidden = torch.zeros(num_layers, batch_size, hidden_size)\n",
        "\n",
        "out, hidden = cell(inputs, hidden) "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps6WnxG6VkB2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "d994c778-4150-43f5-a319-aeeb365748a8"
      },
      "source": [
        "print('Output size:', out.shape)\n",
        "print('Output:', out)\n",
        "print('HIdden size:', hidden.shape)\n",
        "print('Hidden:', hidden.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output size: torch.Size([3, 1, 2])\n",
            "Output: tensor([[[ 0.8381, -0.7957]],\n",
            "\n",
            "        [[ 0.9516, -0.9500]],\n",
            "\n",
            "        [[ 0.9926, -0.9898]]], grad_fn=<StackBackward>)\n",
            "HIdden size: torch.Size([1, 1, 2])\n",
            "Hidden: torch.Size([1, 1, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPMhBXWVCTuq",
        "colab_type": "text"
      },
      "source": [
        "# 一个小例子"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63Dpah7jCYsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "input_size = 4\n",
        "hidden_size = 4\n",
        "batch_size = 1"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29MvJJ_8NvHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx2char = ['e', 'h', 'l', 'o']\n",
        "x_data = [1,0,2,2,3]\n",
        "y_data = [3,1,2,3,2]\n",
        "\n",
        "one_hot_lookup = [[1,0,0,0],\n",
        "          [0,1,0,0],\n",
        "          [0,0,1,0],\n",
        "          [0,0,0,1],                \n",
        "          ]\n",
        "x_one_hot = [one_hot_lookup[x] for x in x_data]\n",
        "\n",
        "inputs = torch.Tensor(x_one_hot).view(-1, batch_size, input_size)\n",
        "labels = torch.LongTensor(y_data).view(-1,1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DAKfRVv2Ut5",
        "colab_type": "text"
      },
      "source": [
        "## 若使用RNNCell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUmVBH7YS_vO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, batch_size):\n",
        "    super(Model, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.rnncell = torch.nn.RNNCell(input_size=self.input_size,\n",
        "                     hidden_size=self.hidden_size)\n",
        "\n",
        "  def forward(self, input, hidden):\n",
        "    hidden = self.rnncell(input, hidden)\n",
        "    return hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return torch.zeros(self.batch_size, self.hidden_size)\n",
        "\n",
        "net = Model(input_size, hidden_size, batch_size)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHlWhsgOWfjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnHivJCrWzN_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "d280a951-bdc3-4fa4-b59e-0b51f0b879b6"
      },
      "source": [
        "for epoch in range(15):\n",
        "  loss = 0\n",
        "  optimizer.zero_grad()\n",
        "  hidden = net.init_hidden()\n",
        "  print('Predicted string:', end='')\n",
        "  for input, label in zip(inputs, labels):\n",
        "    hidden = net(input, hidden)      \n",
        "    # Shape of Inputs:(seqLen, batchSize, inputSize) \n",
        "    # Shape of Input:(batchSize, inputSize)\n",
        "    # Shape of labels:(seqSize, 1) \n",
        "    # Shape of label:(1)\n",
        "    loss += criterion(hidden, label)   # loss因为是多个h产生的loss之和，在计算图中，故不用item\n",
        "    _, idx = hidden.max(dim=1)  # 获取hidden最大值的下标\n",
        "    print(idx2char[idx.item()], end='')\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print(', Epoch [%d/15] loss=%.4f' % (epoch+1, loss.item()))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted string:ooeoo, Epoch [1/15] loss=7.1416\n",
            "Predicted string:ooloo, Epoch [2/15] loss=5.8359\n",
            "Predicted string:ohllh, Epoch [3/15] loss=5.0091\n",
            "Predicted string:ohlll, Epoch [4/15] loss=4.6407\n",
            "Predicted string:ohlll, Epoch [5/15] loss=4.3732\n",
            "Predicted string:ohlll, Epoch [6/15] loss=3.9806\n",
            "Predicted string:ohlll, Epoch [7/15] loss=3.5712\n",
            "Predicted string:ohlol, Epoch [8/15] loss=3.2520\n",
            "Predicted string:ohlol, Epoch [9/15] loss=3.0108\n",
            "Predicted string:ohlol, Epoch [10/15] loss=2.7864\n",
            "Predicted string:ohlol, Epoch [11/15] loss=2.5669\n",
            "Predicted string:ohlol, Epoch [12/15] loss=2.3907\n",
            "Predicted string:ohlol, Epoch [13/15] loss=2.2748\n",
            "Predicted string:ohlol, Epoch [14/15] loss=2.2070\n",
            "Predicted string:ohlol, Epoch [15/15] loss=2.1636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBNcrmd62Nzp",
        "colab_type": "text"
      },
      "source": [
        "## 若使用RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSGs_iCoCAEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "input_size = 4\n",
        "hidden_size = 4\n",
        "batch_size = 1\n",
        "num_layers = 1\n",
        "seq_len = 5"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzMGlSXw2Chp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "  def __init__(self, innput_size, hidden_size, batch_size, num_layers=1):\n",
        "    super(Model, self).__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.batch_size = batch_size\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.rnn = torch.nn.RNN(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=num_layers)\n",
        "\n",
        "  def forward(self, input):\n",
        "    hidden = torch.zeros(self.num_layers,\n",
        "              self.batch_size,\n",
        "              self.hidden_size)\n",
        "    out, _ =self.rnn(input, hidden)\n",
        "    return out.view(-1, self.hidden_size)# reshape out to: (seqLen × batchSize, hiddenSize)\n",
        "\n",
        "net = Model(input_size, hidden_size, batch_size, num_layers)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktlsqmGh6cT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx2char = ['e', 'h', 'l', 'o']\n",
        "x_data = [1,0,2,2,3]\n",
        "y_data = [3,1,2,3,2]\n",
        "\n",
        "one_hot_lookup = [[1,0,0,0],\n",
        "          [0,1,0,0],\n",
        "          [0,0,1,0],\n",
        "          [0,0,0,1],                \n",
        "          ]\n",
        "x_one_hot = [one_hot_lookup[x] for x in x_data]\n",
        "\n",
        "inputs = torch.Tensor(x_one_hot).view(seq_len, batch_size, input_size) # Shape of inputs:(seqLen, batchSize, hiddenSize)\n",
        "labels = torch.LongTensor(y_data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0KBZmleCuZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tj8PgZc9MHi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "a5250773-a6c2-43d1-9d35-90116d6e23d6"
      },
      "source": [
        "for epoch in range(15):\n",
        "  optimizer.zero_grad()\n",
        "  outputs = net(inputs)\n",
        "  loss = criterion(outputs, labels)\n",
        "  loss.backward() \n",
        "  optimizer.step()\n",
        "\n",
        "  _, idx = outputs.max(dim=1)  # 获取hidden最大值的下标\n",
        "  idx = idx.data.numpy()\n",
        "  print('Predicted: ', ''.join([idx2char[x] for x in idx]), end='')\n",
        "  print(', Epoch [%d/15] loss=%.3f' % (epoch+1, loss.item()))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted:  ohooo, Epoch [1/15] loss=1.126\n",
            "Predicted:  ohlll, Epoch [2/15] loss=1.010\n",
            "Predicted:  ohlll, Epoch [3/15] loss=0.931\n",
            "Predicted:  ohlll, Epoch [4/15] loss=0.866\n",
            "Predicted:  ohlol, Epoch [5/15] loss=0.807\n",
            "Predicted:  ohlol, Epoch [6/15] loss=0.745\n",
            "Predicted:  ohlol, Epoch [7/15] loss=0.683\n",
            "Predicted:  ohlol, Epoch [8/15] loss=0.632\n",
            "Predicted:  ohlol, Epoch [9/15] loss=0.591\n",
            "Predicted:  ohlol, Epoch [10/15] loss=0.554\n",
            "Predicted:  ohlol, Epoch [11/15] loss=0.515\n",
            "Predicted:  ohlol, Epoch [12/15] loss=0.474\n",
            "Predicted:  ohlol, Epoch [13/15] loss=0.442\n",
            "Predicted:  ohlol, Epoch [14/15] loss=0.421\n",
            "Predicted:  ohlol, Epoch [15/15] loss=0.410\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lV8rQo2C4S2",
        "colab_type": "text"
      },
      "source": [
        "## 独热向量特点  \n",
        "- 维度太高\n",
        "- 稀疏\n",
        "- 硬编码\n",
        "## 嵌入层(Embedding)--好  \n",
        "- 低维\n",
        "- 稠密\n",
        "- 从数据中学习"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gha08czEMJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.emb = torcch.nn.Embedding(input_size, embedding_size)\n",
        "    self.rnn = torch.nn.RNN(input_size=embedding_size,  \n",
        "                hidden_size = hidden_size,\n",
        "                num_layers=num+layers,\n",
        "                batch_size=True)\n",
        "    self.fc = torch.nn.Linear(hidden_size, num_class)\n",
        "\n",
        "  def forward(self, x):\n",
        "    hidden = torch.zeros(num_layers, x.size(0), hidden_size)\n",
        "    x = self.emb(x) # (batch, aeqLen, embeddingSize)\n",
        "    x, _ = self.rnn(x, hidden)\n",
        "    x = self.fc(x)\n",
        "    return x.view(-1, num_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urvg5gTCF5_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_class = 4\n",
        "input_size = 4\n",
        "hidden_size = 8\n",
        "embedding_size = 10\n",
        "num_layers = 2\n",
        "batch_size = 1\n",
        "seq_len = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO3d4YbfGJrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx2char = ['e', 'h', 'l', 'o']\n",
        "x_data = [1,0,2,2,3]\n",
        "y_data = [3,1,2,3,2]\n",
        "# Input是LongTensor, (batchSize, seqLen)\n",
        "inputs = torch.LongTensor(x_data)\n",
        "labels = torch.LongTensor(y_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz-MT0JLGWXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Model()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}